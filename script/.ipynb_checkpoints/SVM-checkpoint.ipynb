{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocess.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "random_state = 42\n",
    "\n",
    "X = df.loc[:, df.columns != 'prob']\n",
    "y = df['prob']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1)).fit(X_train)\n",
    "\n",
    "# Apply the normalization trained in training data in both training and test sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#knc = LinearSVC()\n",
    "knc = SVC(kernel='linear')\n",
    "knc.fit(X_train, y_train)\n",
    "pred = knc.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix on test set:\\n\", sk.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \", sk.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nF1 score on test set: \", sk.metrics.f1_score(y_test, pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# List of C values to test. We usualy test diverse orders of magnitude\n",
    "Cs = np.logspace(-3, 6, num=10, base=10.0)\n",
    "#Cs = np.logspace(-3, 5, num=9, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "#grid_search = GridSearchCV(LinearSVC(), param_grid, cv=10)\n",
    "grid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=5, n_jobs=-1, scoring='f1_micro', verbose=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Let's plot the 10-fold cross.validation accuracy deppending on C\n",
    "scores = grid_search.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.semilogx(Cs,scores)\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('C')\n",
    "plt.savefig('../figures/svm_linear_C_cv.pdf')\n",
    "\n",
    "parval=grid_search.best_params_\n",
    "cvacc = cross_val_score(SVC(C=parval['C'],kernel='linear'), X=X_train,  y=y_train, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)\n",
    "print('F1 score 5-fold cross on train data= ', cvacc.mean())\n",
    "\n",
    "# Let's apply the best C parameter found to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#knc = LinearSVC(C=parval['C'])\n",
    "svcl = SVC(C=parval['C'], kernel='linear')\n",
    "svcl.fit(X_train, y_train)\n",
    "pred = svcl.predict(X_test)\n",
    "\n",
    "print(\"\\nConfusion matrix on test set:\\n\", sk.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \", sk.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nF1 score on test set: \", sk.metrics.f1_score(y_test, pred, average='micro'))\n",
    "print(\"\\nBest value of parameter C found: \", parval)\n",
    "print(\"\\nNumber of supports: \", np.sum(svcl.n_support_), \"(\",np.sum(np.abs(svcl.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \", np.sum(svcl.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svcp2 = SVC(kernel='poly', degree=2)\n",
    "svcp2.fit(X_train, y_train)\n",
    "\n",
    "pred = svcp2.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sk.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sk.metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Cs = np.logspace(-3, 6, num=10, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "grid_search = GridSearchCV(SVC(kernel='poly', degree=2) , param_grid, cv=5, n_jobs=-1, scoring='f1_micro', verbose=10)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "scores = grid_search.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.semilogx(Cs,scores)\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('C')\n",
    "plt.savefig('../figures/svm_poly_C_cv.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parval = grid_search.best_params_\n",
    "\n",
    "cvacc = cross_val_score(SVC(kernel='poly', degree=2, C=parval['C']) , X=X_train,  y=y_train, cv=5, scoring='f1_micro', n_jobs=-1)\n",
    "print('F1 score 5-fold cross on train data= ', cvacc.mean())\n",
    "\n",
    "svcp2 = SVC(kernel='poly', degree=2, C=parval['C'])\n",
    "svcp2.fit(X_train, y_train)\n",
    "pred = svcp2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nConfusion matrix on test set:\\n\", sk.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \", sk.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nF1 score on test set: \", sk.metrics.f1_score(y_test, pred, average='micro'))\n",
    "print(\"\\nBest combination of parameters found: \",parval)\n",
    "print(\"\\nNumber of supports: \",np.sum(svcp2.n_support_), \"(\",np.sum(np.abs(svcp2.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(svcp2.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svcp3 = SVC(kernel='poly', degree=3)\n",
    "svcp3.fit(X_train, y_train)\n",
    "pred = svcp3.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix on test set:\\n\", sk.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \", sk.metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Cs = np.logspace(-3, 6, num=10, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "grid_search = GridSearchCV(SVC(kernel='poly', degree=3) , param_grid, cv=5, n_jobs=-1, scoring='f1_micro', verbose=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "scores = grid_search.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.semilogx(Cs, scores)\n",
    "plt.ylabel('F1 score')\n",
    "plt.xlabel('C')\n",
    "plt.savefig('../figures/svm_poly3_C_cv.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parval = grid_search.best_params_\n",
    "\n",
    "cvacc = cross_val_score(SVC(kernel='poly', degree=3, C=parval['C']) , X=X_train,  y=y_train, cv=5, scoring='f1_micro', n_jobs=-1)\n",
    "print('F1 score 5-fold cross on train data= ', cvacc.mean())\n",
    "\n",
    "svcp3 = SVC(kernel='poly', degree=3, C=parval['C'])\n",
    "svcp3.fit(X_train, y_train)\n",
    "pred = svcp3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nConfusion matrix on test set:\\n\", sk.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \", sk.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nF1 score on test set: \", sk.metrics.f1_score(y_test, pred, average='micro'))\n",
    "print(\"\\nBest combination of parameters found: \", parval)\n",
    "print(\"\\nNumber of supports: \",np.sum(svcp3.n_support_), \"(\",np.sum(np.abs(svcp3.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(svcp3.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svcrbf = SVC()\n",
    "svcrbf.fit(X_train, y_train)\n",
    "pred = svcrbf.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\", sk.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \", sk.metrics.accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Values we will test for each parameter. When observing results, consider the limits of the\n",
    "# values tested and increase them if necessary\n",
    "gammas = [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "Cs = np.logspace(-1, 6, num=8, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, n_jobs=-1, scoring='f1_micro', verbose=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "parval=grid_search.best_params_\n",
    "\n",
    "# We'll show in a grid, the accuracy for each combination of parameters tester\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "scores = np.array(scores).reshape(len(param_grid['C']), len(param_grid['gamma']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(scores)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar(label='F1 score')\n",
    "plt.grid(b=None)\n",
    "plt.xticks(np.arange(len(param_grid['gamma'])), param_grid['gamma'], rotation='vertical')\n",
    "plt.yticks(np.arange(len(param_grid['C'])), param_grid['C'])\n",
    "plt.savefig(\"../figures/svm_rbf_C_cv.pdf\")\n",
    "\n",
    "parval = grid_search.best_params_\n",
    "print(\"\\nBest combination of parameters found: \", parval)\n",
    "\n",
    "cvacc = cross_val_score(SVC(C=parval['C'], gamma=parval['gamma']) , X=X_train,  y=y_train, cv=5, scoring='f1_micro', n_jobs=-1)\n",
    "print('\\nF1 score 5-fold cross on train data= ', cvacc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "svcrbf = SVC(C=parval['C'], gamma=parval['gamma'])\n",
    "svcrbf.fit(X_train, y_train)\n",
    "pred = svcrbf.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix on test set:\\n\", sk.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \", sk.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nF1 score on test set: \", sk.metrics.f1_score(y_test, pred, average='micro'))\n",
    "print(\"\\nNumber of supports: \",np.sum(svcrbf.n_support_), \"(\",np.sum(np.abs(svcrbf.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(svcrbf.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
